# Data Science Machine Learning Project

## [Titanic Dataset Analysis Summary](https://github.com/prathamgupta36/Data-Science-Machine-Learning-Bootcamp/blob/main/Titanic%20Passenger%20Analysis.ipynb)

The provided code conducts a thorough analysis of the Titanic dataset, encompassing data loading, exploratory data analysis (EDA), data cleaning, and the development of two machine learning models: Logistic Regression and Random Forest Classifier.

### Key Steps:

1. **Importing Packages:**
   - Essential libraries like Pandas, NumPy, Matplotlib, Seaborn, and scikit-learn are imported.

2. **Load and Explore Dataset:**
   - Initial dataset overview, statistical summaries, and categorical variable analysis.

3. **Data Cleaning:**
   - Unnecessary columns dropped.
   - Missing values in 'Age' and 'Embarked' handled.
   - Categorical variables appropriately converted.

4. **Further EDA:**
   - Histograms and visualizations explore age distribution, passenger class, and variable relationships.

5. **Data Processing and Normalization:**
   - Features prepared for machine learning using one-hot encoding and numerical normalization.

6. **Creating ML Models:**
   - Two models (Logistic Regression and Random Forest Classifier) trained and evaluated.

7. **Insights and Suggestions:**
   - Logistic Regression slightly outperforms Random Forest Classifier in accuracy.
   - Suggestions for further analysis and feature engineering are provided.


## [Supermarket Survey Analysis Summary](https://github.com/prathamgupta36/Data-Science-Machine-Learning-Bootcamp/blob/main/Supermarket%20Customer%20Analysis.ipynb)

The code analyzes a supermarket survey dataset, exploring customer demographics and preferences for self-checkout. Two machine learning models, Logistic Regression and Random Forest Classifier, were employed for predicting customer ideas regarding self-checkout.

### Key Steps:

1. **Importing Packages:**
   - Essential libraries such as Pandas, NumPy, Matplotlib, Seaborn, and scikit-learn are imported.

2. **Load and Explore Dataset:**
   - Initial dataset overview, statistical summaries, and categorical variable analysis.

3. **Data Cleaning and EDA:**
   - Delimiter adjusted for proper data comprehension.
   - Descriptive statistics, frequency counts, and visualizations performed.

4. **Data Processing and Normalization:**
   - Unnecessary columns dropped, missing values handled.
   - Categorical variables converted, one-hot encoding applied.
   - Numerical normalization and scaling performed.

5. **Creating ML Models:**
   - Logistic Regression and Random Forest Classifier models trained and evaluated.

6. **Insights and Suggestions:**
   - Key insights from exploratory data analysis presented.
   - Model performance metrics for both models discussed.

7. **Note:**
   - A note explains specific steps taken during data cleaning and processing.

### Credits
This project was part of and inspired by the final project of Hasso Plattner Institute's (HPI) Data Science Bootcamp taught by Mohamed Elhayany and Hendrik Steinbeck.
